# 知网期刊批量爬取工具

这是一个用于批量获取知网期刊信息的自动化工具，支持自定义搜索编码、可设置最大爬取页面数，具有严格的期刊识别机制和完善的反检测功能。

## 功能特点

- ✅ **严格期刊识别**: 基于官方标识严格区分期刊和报纸，只收集真正的期刊
- ✅ **批量搜索支持**: 支持多个地区编码同时搜索
- ✅ **灵活配置**: 可自定义搜索编码、最大页面数、延时参数等
- ✅ **智能翻页**: 自动翻页直到真正的页面结束
- ✅ **完整信息提取**: 获取期刊的详细信息，包括投稿信息
- ✅ **进度保存**: 定期保存进度，支持中断后继续
- ✅ **重复检测**: 自动跳过已存在的期刊
- ✅ **反检测机制**: 随机延时、用户代理等反爬虫检测
- ✅ **详细调试**: 完整的调试信息输出，便于问题诊断
- ✅ **Excel 输出**: 自动保存为 Excel 格式，便于后续处理

## 安装依赖

```bash
npm install
```

或者使用 pnpm:

```bash
pnpm install
```

## 使用方法

### 快速开始（推荐）

直接运行批量爬取脚本：

```bash
npm run batch
```

或者：

```bash
node run-batch.js
```

程序将显示当前配置并询问确认，输入 `y` 或 `yes` 开始爬取。

### 单个期刊测试

如果想先测试单个期刊的爬取效果：

```bash
npm run single
```

## 配置说明

### 主要配置参数

编辑 `run-batch.js` 文件中的 `USER_CONFIG` 部分进行自定义配置：

```javascript
const USER_CONFIG = {
  // 搜索编码配置（选择以下方式之一）

  // 方式1：使用预设编码组合
  // searchCodes: config.SEARCH_CODES.DEFAULT,        // 北京和上海
  // searchCodes: config.SEARCH_CODES.MAJOR_CITIES,   // 主要城市
  // searchCodes: config.SEARCH_CODES.ALL_REGIONS,    // 更多地区

  // 方式2：完全自定义搜索编码
  searchCodes: [
    "11-", // 北京
    "31-", // 上海
    "21-", // 辽宁
    "44-", // 广东
    "37-", // 山东
    "51-", // 四川
    "32-", // 江苏
    "33-", // 浙江
    // 可根据需要添加更多地区编码
  ],

  // 爬取页面数配置
  maxPages: 0, // 全局最大页面数，0 = 无限制，爬到底
  maxPagesPerCode: 30, // 每个搜索编码最大页面数

  // 延时配置（毫秒）
  delayBetweenPages: [3000, 6000], // 页面间随机延时范围
  delayBetweenCodes: [15000, 30000], // 搜索编码间随机延时范围

  // 其他配置
  saveFrequency: 3, // 每处理多少页保存一次进度
  verbose: true, // 是否显示详细日志
};
```

### 地区编码对照表

| 编码 | 地区   | 编码 | 地区 | 编码 | 地区 | 编码 | 地区 |
| ---- | ------ | ---- | ---- | ---- | ---- | ---- | ---- |
| 11-  | 北京   | 31-  | 上海 | 41-  | 河南 | 51-  | 四川 |
| 12-  | 天津   | 32-  | 江苏 | 42-  | 湖北 | 52-  | 贵州 |
| 13-  | 河北   | 33-  | 浙江 | 43-  | 湖南 | 53-  | 云南 |
| 14-  | 山西   | 34-  | 安徽 | 44-  | 广东 | 54-  | 西藏 |
| 15-  | 内蒙古 | 35-  | 福建 | 45-  | 广西 | 61-  | 陕西 |
| 21-  | 辽宁   | 36-  | 江西 | 46-  | 海南 | 62-  | 甘肃 |
| 22-  | 吉林   | 37-  | 山东 | 50-  | 重庆 | 63-  | 青海 |
| 23-  | 黑龙江 | 37-  | 山东 | 50-  | 重庆 | 64-  | 宁夏 |
| ...  | ...    | ...  | ...  | ...  | ...  | 65-  | 新疆 |

### 配置文件说明

- **`run-batch.js`**: 主要配置文件，用户可以在此修改所有爬取参数
- **`src/config.js`**: 基础配置文件，包含系统级别的设置
- **`batch-crawler.js`**: 核心爬虫实现，一般不需要修改

## 期刊识别机制

程序采用严格的期刊识别标准，确保只收集真正的期刊：

### 识别标准

1. **官方标识检查**：

   - `<span>期刊</span>` → 确认为期刊
   - `<span>报纸</span>` → 排除报纸

2. **CSS 类检查**：

   - `qk_tag` → 期刊标识
   - `bz_tag` → 报纸标识（排除）

3. **英文标识检查**：
   - `Journal` → 期刊
   - `Newspaper` → 报纸（排除）

### 调试信息

程序会输出详细的识别过程：

```
类型标签完整内容: "期刊Journal"
标签span内容: "期刊"
em标签class: "qk_tag"
b标签内容: "Journal"
✓ 确认为期刊
期刊判断结果: true (官方标记为期刊)
✓ 添加期刊: "期刊名称"
```

## 输出数据说明

程序会自动在项目根目录生成 `zhiwang_journals_complete.xlsx` 文件，包含以下字段：

### 基本信息

- 期刊名称
- CN 号
- ISSN
- 数据库标识
- 曾用刊名
- 主办单位
- 出版周期
- 出版地
- 语种
- 开本
- 创刊时间

### 出版信息

- 专辑名称
- 专题名称
- 出版文献量
- 总下载次数
- 总被引次数

### 评价信息

- 复合影响因子
- 复合影响因子年份
- 综合影响因子
- 综合影响因子年份
- 数据库收录列表

### 投稿信息

- WJCI 分区
- 投稿出版周期
- 投稿是否收费
- 主编
- 副主编
- 官网网址
- 投稿网址
- 投稿邮箱
- 咨询邮箱
- 编辑部地址
- 联系电话
- 获取时间

## 使用注意事项

### 网络和性能

- 确保网络连接稳定
- 建议在网络空闲时间进行大量爬取
- 程序运行在可视化浏览器模式，便于观察进度

### 反检测设置

- 程序内置了随机延时机制，避免被限制访问
- 建议不要过度缩短延时时间
- 如遇到验证码，可以在浏览器中手动处理

### 数据安全

- 程序会定期保存进度，防止数据丢失
- 支持中断后继续运行（自动跳过已处理的期刊）
- 建议定期备份 Excel 文件

### 优雅停止

- 使用 `Ctrl+C` 可以优雅停止程序
- 停止时会自动保存当前进度并清理资源

## 项目结构

```
zhiwang/
├── src/
│   ├── config.js           # 基础配置文件
│   ├── antiDetection.js    # 反检测模块
│   └── excelHandler.js     # Excel处理模块
├── batch-crawler.js        # 批量爬虫核心类
├── run-batch.js           # 批量爬虫启动脚本（主要配置文件）
├── get-single-journal.js  # 单个期刊测试脚本
├── package.json           # 项目依赖配置
├── pnpm-lock.yaml         # 依赖锁定文件
└── README.md              # 使用说明（本文件）
```

## 技术实现

### 核心技术栈

- **Node.js**: 运行环境
- **Playwright**: 浏览器自动化框架
- **XLSX**: Excel 文件处理库

### 主要模块

- **AntiDetection**: 反检测机制，包括随机延时、用户代理伪装等
- **ExcelHandler**: Excel 文件处理，支持增量保存和去重
- **BatchCrawler**: 批量爬虫核心逻辑

### 开发说明

如需修改核心逻辑，主要文件说明：

- **`batch-crawler.js`**: 批量爬虫的核心实现，包含期刊识别、翻页、数据提取等逻辑
- **`run-batch.js`**: 用户配置和启动脚本，这是主要的配置文件
- **`src/config.js`**: 基础配置，包含选择器定义、预设编码组合等
- **`src/excelHandler.js`**: Excel 文件处理逻辑，支持数据格式化和去重
- **`src/antiDetection.js`**: 反检测机制实现

## 版本更新记录

### v1.0.0

- ✅ 实现基础的批量爬取功能
- ✅ 严格的期刊识别机制
- ✅ 完整的反检测功能
- ✅ 详细的调试信息输出
- ✅ 灵活的配置选项
- ✅ 自动进度保存和恢复
